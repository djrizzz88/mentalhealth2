import streamlit as st
import torch
import json
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ================================
# 1ï¸âƒ£ Load model & tokenizer
# ================================
MODEL_NAME = "jordan88rali/mental-health-chatbot-v2"

@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
    return tokenizer, model

tokenizer, model = load_model()

# ================================
# 2ï¸âƒ£ Load label map & fix format
# ================================
with open("label_map.json", "r") as f:
    label_map = json.load(f)

if isinstance(label_map, list):
    id2label = {i: label for i, label in enumerate(label_map)}
else:
    id2label = {v: k for k, v in label_map.items()}

# ================================
# 3ï¸âƒ£ Streamlit UI setup
# ================================
st.set_page_config(page_title="ğŸ§  Mental Health Chatbot", page_icon="ğŸ’¬")
st.title("ğŸ§  Mental Health Support Chatbot")
st.markdown("Hello ğŸ‘‹. Iâ€™m here to talk and listen. How are you feeling today?")

# Store conversation
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ================================
# 4ï¸âƒ£ Predict intent function
# ================================
def predict_intent(user_text):
    inputs = tokenizer(user_text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    prediction = torch.argmax(outputs.logits, dim=1).item()
    intent = id2label[prediction]
    return intent

# ================================
# 5ï¸âƒ£ Chat interaction
# ================================
if prompt := st.chat_input("Type your message..."):
    # Add user message to history
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Predict intent
    intent = predict_intent(prompt)

    # Generate a human-like bot reply
    if intent == "greeting":
        bot_reply = "Hello! How are you feeling today? ğŸŒ¼"
    elif intent == "sad":
        bot_reply = "Iâ€™m sorry youâ€™re feeling this way. Do you want to talk more about it? ğŸ’™"
    elif intent == "happy":
        bot_reply = "Thatâ€™s wonderful to hear! ğŸŒŸ Whatâ€™s been going well for you?"
    elif intent == "stressed":
        bot_reply = "I understand stress can be tough. Want to share whatâ€™s on your mind? ğŸ¤"
    elif intent == "suicide":
        bot_reply = "Iâ€™m really concerned about your safety. You are not alone â€” please call a suicide helpline immediately. ğŸ“"
    else:
        bot_reply = f"I think you might be feeling **{intent}**. Would you like to tell me more?"

    # Add bot reply to history
    st.session_state.messages.append({"role": "assistant", "content": bot_reply})
    with st.chat_message("assistant"):
        st.markdown(bot_reply)
